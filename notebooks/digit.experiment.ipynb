{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4376497a",
   "metadata": {},
   "source": [
    "# Cài đặt triển khai mô hình toàn diện với kiến trúc đề xuất theo Pipeline (Khởi tạo kiến trúc, Train, Test)\n",
    "###Bài toán cài đặt:\n",
    "#### Nhận diện chữ số viết tay (bộ dữ liệu gồm 50k mẫu train, 10k mẫu Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d256c26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Các thư viện cần dùng cho dự án\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import random\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "from fgi import *\n",
    "from torch import nn, optim\n",
    "from torchmetrics import Accuracy\n",
    "from pytorch_metric_learning import losses, miners, samplers\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55d1f69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Các Constant cài đặt mặc định\n",
    "IMG_SHAPE = (1, 28, 28) # C, H, W (ảnh xám mặc định)\n",
    "PHI_DIM = 128\n",
    "OPTIONS = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "NUM_CLASSES = len(OPTIONS)\n",
    "DEFAULT_LR = 0.2\n",
    "MAX_EXAMPLES = 1000 # Dùng cho embedding\n",
    "NORMALIZE_IMAGE = (0.1307,), (0.3081,)\n",
    "NUM_WORKERS = 7\n",
    "BATCH_SIZE = 32\n",
    "STORAGE_DATA = \"../data/mnist_digit\"\n",
    "PROBLEM_ID = \"digit_classifier\"\n",
    "EXPERIMENT_TENSORBOARD_NAME = PROBLEM_ID\n",
    "EXPRIMENT_TENSORBOARD_PATH = \"../experiment/\"\n",
    "SEED_CODE = 131006 # Random id dùng cho sinh dữ liệu\n",
    "TRAIN_SIZE = 0.8 # 80% dữ liệu train sẽ được đem đi đào tạo, 20% cho validation\n",
    "NUM_SAMPLE_PER_CLASS = 4 # Số sample mỗi label dành cho học không gian embedding\n",
    "DROPOUT = 0.2 # Công dụng regularier, cấu hình cho nn.Dropout\n",
    "TRIPLER_MARGIN = 28.6 # Độ khác biệt tối thiểu giữa anchor và positive, dùng cho biệt hoá không gian embedding\n",
    "STRATEGY_ANCHOR_POSITIVE = \"hard\"\n",
    "DEVICE = \"cpu\"\n",
    "PATIENCE = 3 # Số lượt đợi không cải thiện\n",
    "LAMBDA_CLASSIFY = 1. # Trọng số đánh giá tầm quan trọng mục tiêu phân loại\n",
    "LAMBDA_EMBEDDING = 1. # Trọng số đánh giá tầm quan trọng mục tiêu biệt hoá không gian\n",
    "ILLUSTRATION_EXAMPLES = 1000 # Giới hạn số mẫu dùng cho show projector trong tensorboard\n",
    "MAX_EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6ac7697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cấu hình pytorch đảm bảo thí nghiệm\n",
    "torch.manual_seed(SEED_CODE)\n",
    "random.seed(SEED_CODE)\n",
    "np.random.seed(SEED_CODE)\n",
    "torch.cuda.manual_seed(SEED_CODE)\n",
    "torch.cuda.manual_seed_all(SEED_CODE)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665a5abc",
   "metadata": {},
   "source": [
    "## Chuẩn bị dữ liệu huấn luyện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72645277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển đổi và tăng cường dữ liêụ\n",
    "# Định dạng transform mặc định\n",
    "default_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(*NORMALIZE_IMAGE)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4808f7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = torchvision.datasets.MNIST(STORAGE_DATA, train=True, download=True, transform=default_transform)\n",
    "\n",
    "# Chia tập train và validation\n",
    "train_size = int(len(full_dataset) * TRAIN_SIZE)\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Lấy bộ dữ liệu test\n",
    "test_dataset = torchvision.datasets.MNIST(STORAGE_DATA, train=False, transform=default_transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8fe7a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước toàn bộ dữ liệu đào tạo: 60000\n",
      "Kích thước dữ liệu cho training: 48000\n",
      "Kích thước dữ liệu cho validation: 12000\n",
      "Kích thước dữ liệu cho test: 10000\n"
     ]
    }
   ],
   "source": [
    "# In thử thông tin bộ dữ liệu\n",
    "print(f\"Kích thước toàn bộ dữ liệu đào tạo: {len(full_dataset)}\")\n",
    "print(f\"Kích thước dữ liệu cho training: {train_size}\")\n",
    "print(f\"Kích thước dữ liệu cho validation: {val_size}\")\n",
    "print(f\"Kích thước dữ liệu cho test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc66d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiến hành tạo các DataLoader\n",
    "# Lấy tập train_labels dành cho sampler hỗ trợ học ko gian biểu diễn\n",
    "train_labels = full_dataset.targets[train_dataset.indices]\n",
    "embedding_sampler = samplers.MPerClassSampler(train_labels, m=NUM_SAMPLE_PER_CLASS, batch_size=BATCH_SIZE, length_before_new_iter=train_size)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=embedding_sampler, num_workers=NUM_WORKERS, persistent_workers=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, persistent_workers=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61e36ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 5, 6,  ..., 0, 9, 6])\n"
     ]
    }
   ],
   "source": [
    "# In thử train_labels, soát lỗi\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dfe58b",
   "metadata": {},
   "source": [
    "## Kiến trúc mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab543dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lớp dùng cho khai thác kết quả\n",
    "class DigitExploiter(Exploiter):\n",
    "    def __init__(self, digit, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)  \n",
    "        self.digit = digit\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.metadata[\"type\"]}(digit={self.digit})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05aa5050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lớp hành vi của vấn đề\n",
    "class DigitClassifier(NonCodeProblem):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(PROBLEM_ID, DigitExploiter, *args, **kwargs)\n",
    "        self._r = RepresentLayer([ \n",
    "            ImageRepresent(img_shape=IMG_SHAPE, patch_size=7, num_heads=1, phi_dim=PHI_DIM),  \n",
    "            ImageRepresent(img_shape=IMG_SHAPE, patch_size=7, num_heads=1, phi_dim=PHI_DIM)\n",
    "        ], output_dim=PHI_DIM)\n",
    "        self._en = EnhanceRepresentUnit(phi_dim=PHI_DIM)\n",
    "        self._po = PropertyUnit(phi_dim=PHI_DIM)\n",
    "        self._spe = ChooseOptions(1, options=OPTIONS, property_name=\"digit\", phi_dim=PHI_DIM)\n",
    "    \n",
    "    def recognize_unknown(self, x, *args, **kwargs):\n",
    "        x = self._r(x)\n",
    "        x = x.mean(dim = 1)\n",
    "        x = self._en.embedding(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, skip_avatar : bool = False, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Lan truyền, đại diện cho cách suy luận, cách giải quyết vấn đề,\n",
    "        skip_avatar (bool) : bỏ qua việc xuất kết quả đại diện vấn đề\n",
    "        \"\"\"\n",
    "        q1 = self._r(x)\n",
    "        q1 = q1.mean(dim = 1)\n",
    "        \n",
    "        q_root = self._en(q1)\n",
    "        q = self._po(q_root)\n",
    "        q = self._spe(q_root + q)\n",
    "        \n",
    "        if skip_avatar:\n",
    "            return q\n",
    "        \n",
    "        return q, self._en.embedding(q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6612f652",
   "metadata": {},
   "source": [
    "## Cấu hình huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7d5be77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viết lớp Learner dành riêng cho việc học đào tạo vấn đề\n",
    "class DigitClassifierLearner(LightningLearner):\n",
    "    def __init__(self, problem, *args, **kwargs):\n",
    "        super().__init__(problem, *args, **kwargs)\n",
    "        self._classify = nn.CrossEntropyLoss()\n",
    "        self._specialized_space = losses.ArcFaceLoss(num_classes=NUM_CLASSES, embedding_size=PHI_DIM, margin=TRIPLER_MARGIN)\n",
    "        # self._miner = miners.TripletMarginMiner(margin=TRIPLER_MARGIN, type_of_triplets=STRATEGY_ANCHOR_POSITIVE)\n",
    "        self._train_accuracy = Accuracy(task=\"multiclass\", num_classes=NUM_CLASSES)\n",
    "        self._val_accuracy = Accuracy(task=\"multiclass\", num_classes=NUM_CLASSES)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # Kết hợp thêm chiến lược scheduler\n",
    "        optimizer = optim.AdamW(self._problem.parameters(), lr=0.001)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=PATIENCE - 2)\n",
    "        return { \"optimizer\" : optimizer, \"lr_scheduler\" : scheduler, \"monitor\" : \"val/loss\" }\n",
    "\n",
    "    def training_step(self, batch, batch_idx, *args, **kwargs):\n",
    "        x, y = batch\n",
    "        y_predicted = self(x)\n",
    "\n",
    "        loss, ce, triplet = self._aggerate_loss(y_predicted, y)\n",
    "        self._train_accuracy.update(y_predicted[0], y)\n",
    "        \n",
    "        self.log(\"train/loss\", loss, prog_bar=True, logger=True, on_epoch=True, on_step=True)\n",
    "        self.log(\"train/ce\", ce, prog_bar=True, logger=True, on_epoch=True)\n",
    "        self.log(\"train/triplet\", triplet, prog_bar=True, logger=True, on_epoch=True)\n",
    "        self.log(\"train/acc\", self._train_accuracy, prog_bar=True, on_epoch=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx, *args, **kwargs):\n",
    "        x, y = batch\n",
    "        y_predicted = self(x)\n",
    "\n",
    "        loss, ce, triplet = self._aggerate_loss(y_predicted, y)\n",
    "        self._val_accuracy.update(y_predicted[0], y)\n",
    "\n",
    "        self.log(\"val/loss\", loss, prog_bar=True, logger=True, on_epoch=True)\n",
    "        self.log(\"val/acc\", self._val_accuracy, prog_bar=True, logger=True, on_epoch=True)\n",
    "        self.log(\"val/ce\", ce, prog_bar=True, logger=True, on_epoch=True)\n",
    "        self.log(\"val/triplet\", triplet, prog_bar=True, logger=True, on_epoch=True)\n",
    "\n",
    "    def on_train_batch_end(self, outputs, batch, batch_idx):\n",
    "        lr = self.trainer.optimizers[0].param_groups[0]['lr']\n",
    "        self.log(\"lr\", lr, logger=True, on_epoch=True)\n",
    "\n",
    "    def _aggerate_loss(self, y_predicted, y, *args, **kwargs):\n",
    "        y_hat, emb = y_predicted\n",
    "\n",
    "        ce = self._classify(y_hat, y)\n",
    "        triplet = self._specialized_space(emb, y)\n",
    "\n",
    "        loss = LAMBDA_CLASSIFY * ce + LAMBDA_EMBEDDING * triplet\n",
    "\n",
    "        return loss, ce, triplet\n",
    "    \n",
    "    def test_step(self, batch, *args, **kwargs):\n",
    "        x, y = batch\n",
    "        y_predicted = self(x)\n",
    "\n",
    "        loss, __, __ = self._aggerate_loss(y_predicted, y)\n",
    "        self._val_accuracy.update(y_predicted[0], y)\n",
    "\n",
    "        self.log(\"test/loss\", loss, prog_bar=True, on_epoch=True, logger=True)\n",
    "        self.log(\"test/acc\", self._val_accuracy, prog_bar=True, logger=True, on_epoch=True)\n",
    "    \n",
    "    def _get_embedding(self, iterators):\n",
    "        # Hiển thị thử embedding\n",
    "        collected = 0\n",
    "\n",
    "        all_imgs = []\n",
    "        all_labels = []\n",
    "        all_embeds = []\n",
    "\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in iterators:\n",
    "                x, y = batch\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "\n",
    "                # Encode ảnh thành vector đặc trưng (ví dụ: self._problem.encode)\n",
    "                embedding = self._problem.recognize_unknown(x)\n",
    "\n",
    "                all_imgs.append(x.cpu())\n",
    "                all_labels.append(y.cpu())\n",
    "                all_embeds.append(embedding.cpu())\n",
    "\n",
    "                collected += x.size(0)\n",
    "                if collected >= ILLUSTRATION_EXAMPLES:\n",
    "                    break  # Dừng sớm nếu vượt quá max_examples\n",
    "        \n",
    "        all_imgs = torch.cat(all_imgs, dim=0)[:ILLUSTRATION_EXAMPLES]\n",
    "        all_labels = torch.cat(all_labels, dim=0)[:ILLUSTRATION_EXAMPLES]\n",
    "        all_embeds = torch.cat(all_embeds, dim=0)[:ILLUSTRATION_EXAMPLES]\n",
    "\n",
    "        return all_imgs, all_labels, all_embeds\n",
    "\n",
    "    def on_train_end(self):\n",
    "        all_imgs, all_labels, all_embeds = self._get_embedding(self.trainer.val_dataloaders)\n",
    "        self.logger.experiment.add_embedding(\n",
    "            mat=all_embeds,\n",
    "            metadata=[str(label.item()) for label in all_labels],\n",
    "            label_img=all_imgs,\n",
    "            global_step=self.global_step,\n",
    "            tag=\"train/embedding\"\n",
    "        )\n",
    "\n",
    "    def on_test_end(self):\n",
    "        all_imgs, all_labels, all_embeds = self._get_embedding(self.trainer.test_dataloaders)\n",
    "        self.logger.experiment.add_embedding(\n",
    "            mat=all_embeds,\n",
    "            metadata=[str(label.item()) for label in all_labels],\n",
    "            label_img=all_imgs,\n",
    "            global_step=self.global_step,\n",
    "            tag=\"test/embedding\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64c28bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(fgi.learner.LightningLearner.LightningLearner,\n",
       " fgi.learner.Learner,\n",
       " lightning.pytorch.core.module.LightningModule,\n",
       " abc.ABC,\n",
       " lightning.fabric.utilities.device_dtype_mixin._DeviceDtypeModuleMixin,\n",
       " lightning.pytorch.core.mixins.hparams_mixin.HyperparametersMixin,\n",
       " lightning.pytorch.core.hooks.ModelHooks,\n",
       " lightning.pytorch.core.hooks.DataHooks,\n",
       " lightning.pytorch.core.hooks.CheckpointHooks,\n",
       " torch.nn.modules.module.Module,\n",
       " object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hiển thị thử mối quan hệ kế thừa\n",
    "LightningLearner.__mro__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008f33f1",
   "metadata": {},
   "source": [
    "# Phần thao tác chính, phối hợp các thành phần ở trên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd8432fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'DigitClassifier',\n",
       " 'default_exploiter': 'DigitExploiter',\n",
       " 'call_update': True,\n",
       " 'layers': ['_r'],\n",
       " 'units': ['fc2b842a-e054-48da-8c38-65a6ee5a8f67',\n",
       "  '14369b48-48a5-4f13-a437-fb9f9a7a2ab6',\n",
       "  'a15005e4-a400-4a93-95b1-29094bd88b6e',\n",
       "  'd0a4a325-d60b-4b1d-bc17-b892b299d84d',\n",
       "  'bfd1b5c0-4109-44ad-84d5-6069bfcd2812'],\n",
       " 'properties': ['digit']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Khởi tạo bộ giải quyết\n",
    "solver = DigitClassifier()\n",
    "# Thử xem các cấu hình metadata\n",
    "solver.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e54ae93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo bộ học\n",
    "learner = DigitClassifierLearner(solver)\n",
    "learner.compile()\n",
    "# Dùng cho vẽ đồ thị lan truyền\n",
    "learner.example_input_array = torch.randn(1, 1, 28, 28, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa04d3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[-0.0349,  0.4046,  0.2125,  0.0635, -0.2107,  0.0188, -0.3013,  0.5342,\n",
      "          0.0666, -0.1598]], grad_fn=<AddmmBackward0>), tensor([[ 1.2526e-01, -1.1781e-01,  5.3821e-02,  2.5770e-02, -6.7324e-02,\n",
      "          2.7504e-02,  9.0435e-03, -1.0721e-01, -9.9266e-02, -1.6187e-01,\n",
      "          2.0328e-02, -1.3367e-02,  9.8793e-02, -2.9920e-02, -7.0345e-02,\n",
      "          1.7222e-02,  9.5359e-02,  8.3620e-02, -1.1969e-01,  6.8430e-02,\n",
      "          2.0422e-02,  1.2440e-02,  5.5009e-02, -6.1053e-02,  5.3340e-02,\n",
      "         -1.2076e-01,  8.4601e-02,  1.8055e-01, -1.9966e-02,  4.7596e-02,\n",
      "          3.7765e-02, -3.7254e-02, -8.8597e-02, -5.1497e-02,  1.5733e-01,\n",
      "         -1.9636e-03, -4.5517e-02, -1.0543e-01, -2.2419e-01,  9.0068e-02,\n",
      "         -2.7879e-02, -1.1419e-02,  7.1065e-02, -4.0827e-02, -1.1615e-02,\n",
      "         -8.7144e-02, -1.2128e-02,  1.2616e-01, -1.5050e-01, -6.7234e-02,\n",
      "         -1.6145e-01,  1.7606e-01, -8.5293e-02,  1.0005e-01,  1.4408e-02,\n",
      "         -2.2719e-02,  1.1610e-01,  1.1428e-01,  6.9783e-03, -6.3084e-03,\n",
      "         -1.2781e-01, -7.7787e-02, -3.6691e-02, -9.9188e-02,  5.2627e-02,\n",
      "         -1.4554e-02,  1.1649e-02,  1.8154e-01,  1.3593e-02,  3.5537e-02,\n",
      "         -7.2125e-02,  1.5646e-01, -1.2972e-02,  1.0797e-01, -1.0398e-01,\n",
      "         -1.0904e-01,  6.5467e-02, -1.7900e-01,  1.2883e-01,  3.9979e-02,\n",
      "         -4.2507e-02, -1.1452e-01,  3.7282e-02,  6.0270e-03, -9.3577e-02,\n",
      "         -5.5029e-03,  1.7963e-03,  6.2869e-03, -1.2143e-01, -4.0653e-02,\n",
      "         -2.0441e-03, -2.5960e-02,  5.1811e-02, -8.5114e-02, -9.2731e-02,\n",
      "         -4.7904e-03,  7.5797e-02, -6.7301e-02,  1.8488e-02,  7.6059e-03,\n",
      "         -6.4470e-02,  1.9213e-01, -2.8668e-02, -1.1175e-01, -5.4104e-02,\n",
      "         -2.2627e-02, -8.4799e-02,  1.5066e-01,  1.4912e-01,  9.6102e-03,\n",
      "          1.2950e-01,  3.9058e-05,  8.9424e-02,  6.4234e-02, -2.6073e-02,\n",
      "          4.8453e-02,  1.1396e-01,  1.3009e-01, -1.1808e-01,  1.3917e-01,\n",
      "          1.0330e-01, -7.7011e-03, -1.3636e-01,  3.1020e-03, -1.0162e-02,\n",
      "         -6.8999e-02, -1.4440e-01, -6.1192e-02]], grad_fn=<DivBackward0>))\n"
     ]
    }
   ],
   "source": [
    "# Thử hiển thị và chạy thử solver\n",
    "y_predicted = solver(learner.example_input_array)\n",
    "print(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "218561cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cấu hình logger, callbacks\n",
    "logger = TensorBoardLogger(EXPRIMENT_TENSORBOARD_PATH, EXPERIMENT_TENSORBOARD_NAME, log_graph=True)\n",
    "early = EarlyStopping(\"val/loss\", patience=PATIENCE, verbose=True)\n",
    "best_checkpoint = ModelCheckpoint(dirpath=f\"../database/{PROBLEM_ID}\", filename=\"best\", monitor=\"val/loss\", verbose=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2538b91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "e:\\simulations\\implementations\\env\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:658: Checkpoint directory E:\\simulations\\implementations\\database\\digit_classifier exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type               | Params | Mode  | In sizes | Out sizes\n",
      "-----------------------------------------------------------------------------------------\n",
      "0 | _problem           | DigitClassifier    | 184 K  | train | ?        | ?        \n",
      "1 | _classify          | CrossEntropyLoss   | 0      | train | ?        | ?        \n",
      "2 | _specialized_space | ArcFaceLoss        | 1.3 K  | train | ?        | ?        \n",
      "3 | _train_accuracy    | MulticlassAccuracy | 0      | train | ?        | ?        \n",
      "4 | _val_accuracy      | MulticlassAccuracy | 0      | train | ?        | ?        \n",
      "-----------------------------------------------------------------------------------------\n",
      "185 K     Trainable params\n",
      "0         Non-trainable params\n",
      "185 K     Total params\n",
      "0.741     Total estimated model params size (MB)\n",
      "34        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1500/1500 [02:52<00:00,  8.71it/s, v_num=12, train/loss_step=12.60, train/ce_step=0.616, train/triplet_step=12.00, val/loss=12.80, val/acc=0.804, val/ce=0.633, val/triplet=12.20, train/loss_epoch=20.00, train/ce_epoch=1.060, train/triplet_epoch=18.90, train/acc_epoch=0.653]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved. New best score: 12.799\n",
      "Epoch 0, global step 1500: 'val/loss' reached 12.79865 (best 12.79865), saving model to 'E:\\\\simulations\\\\implementations\\\\database\\\\digit_classifier\\\\best-v2.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  82%|████████▏ | 1232/1500 [02:17<00:29,  8.94it/s, v_num=12, train/loss_step=10.20, train/ce_step=0.503, train/triplet_step=9.730, val/loss=12.80, val/acc=0.804, val/ce=0.633, val/triplet=12.20, train/loss_epoch=20.00, train/ce_epoch=1.060, train/triplet_epoch=18.90, train/acc_epoch=0.653]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1056\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1055\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\lightning\\pytorch\\loops\\training_epoch_loop.py:152\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\lightning\\pytorch\\loops\\training_epoch_loop.py:344\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer.lightning_module.automatic_optimization:\n\u001b[32m    343\u001b[39m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m     batch_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mautomatic_optimization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:192\u001b[39m, in \u001b[36m_AutomaticOptimization.run\u001b[39m\u001b[34m(self, optimizer, batch_idx, kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m result = closure.consume_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:270\u001b[39m, in \u001b[36m_AutomaticOptimization._optimizer_step\u001b[39m\u001b[34m(self, batch_idx, train_step_and_backward_closure)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moptimizer_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:176\u001b[39m, in \u001b[36m_call_lightning_module_hook\u001b[39m\u001b[34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\lightning\\pytorch\\core\\module.py:1328\u001b[39m, in \u001b[36mLightningModule.optimizer_step\u001b[39m\u001b[34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[39m\n\u001b[32m   1304\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[32m   1305\u001b[39m \u001b[33;03mthe optimizer.\u001b[39;00m\n\u001b[32m   1306\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1326\u001b[39m \n\u001b[32m   1327\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1328\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\lightning\\pytorch\\core\\optimizer.py:154\u001b[39m, in \u001b[36mLightningOptimizer.step\u001b[39m\u001b[34m(self, closure, **kwargs)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m._on_after_step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:239\u001b[39m, in \u001b[36mStrategy.optimizer_step\u001b[39m\u001b[34m(self, optimizer, closure, model, **kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl.LightningModule)\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecision_plugin\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\precision.py:123\u001b[39m, in \u001b[36mPrecision.optimizer_step\u001b[39m\u001b[34m(self, optimizer, model, closure, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m closure = partial(\u001b[38;5;28mself\u001b[39m._wrap_closure, model, optimizer, closure)\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\torch\\optim\\optimizer.py:485\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    481\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    482\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\torch\\optim\\optimizer.py:79\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\torch\\optim\\adam.py:225\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    224\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.enable_grad():\n\u001b[32m--> \u001b[39m\u001b[32m225\u001b[39m         loss = \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.param_groups:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\precision.py:109\u001b[39m, in \u001b[36mPrecision._wrap_closure\u001b[39m\u001b[34m(self, model, optimizer, closure)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03mhook is called.\u001b[39;00m\n\u001b[32m    104\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m \n\u001b[32m    108\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m closure_result = \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[38;5;28mself\u001b[39m._after_closure(model, optimizer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:146\u001b[39m, in \u001b[36mClosure.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> Optional[Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28mself\u001b[39m._result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result.loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:131\u001b[39m, in \u001b[36mClosure.closure\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;129m@torch\u001b[39m.enable_grad()\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> ClosureResult:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m step_output.closure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:319\u001b[39m, in \u001b[36m_AutomaticOptimization._training_step\u001b[39m\u001b[34m(self, kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m trainer = \u001b[38;5;28mself\u001b[39m.trainer\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m training_step_output = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtraining_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.strategy.post_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:328\u001b[39m, in \u001b[36m_call_strategy_hook\u001b[39m\u001b[34m(trainer, hook_name, *args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer.strategy.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:391\u001b[39m, in \u001b[36mStrategy.training_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    390\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_redirection(\u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.lightning_module, \u001b[33m\"\u001b[39m\u001b[33mtraining_step\u001b[39m\u001b[33m\"\u001b[39m, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mDigitClassifierLearner.training_step\u001b[39m\u001b[34m(self, batch, batch_idx, *args, **kwargs)\u001b[39m\n\u001b[32m     18\u001b[39m x, y = batch\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m y_predicted = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m loss, ce, triplet = \u001b[38;5;28mself\u001b[39m._aggerate_loss(y_predicted, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\notebooks\\..\\fgi\\learner\\LightningLearner.py:18\u001b[39m, in \u001b[36mLightningLearner.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_problem\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mDigitClassifier.forward\u001b[39m\u001b[34m(self, x, skip_avatar, *args, **kwargs)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[33;03mLan truyền, đại diện cho cách suy luận, cách giải quyết vấn đề,\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[33;03mskip_avatar (bool) : bỏ qua việc xuất kết quả đại diện vấn đề\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m q1 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_r\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m q1 = q1.mean(dim = \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\notebooks\\..\\fgi\\layer\\RepresentLayer.py:15\u001b[39m, in \u001b[36mRepresentLayer.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi_dim\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mphi_dim\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\notebooks\\..\\fgi\\layer\\ForwardLayer.py:30\u001b[39m, in \u001b[36mNonCodeForwardLayer.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, unit \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m._units):\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     tempo[i] = \u001b[43munit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m tempo = tempo.transpose(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\notebooks\\..\\fgi\\problem\\vision\\represent.py:75\u001b[39m, in \u001b[36mImageRepresent.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, *args, **kwargs):\n\u001b[32m     74\u001b[39m     \u001b[38;5;66;03m# Lấy kết quả từ cls làm kết quả đại diện\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     x, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x[:, \u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\notebooks\\..\\fgi\\problem\\vision\\represent.py:68\u001b[39m, in \u001b[36mImageRepresent._forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# x = self._dropout(x)\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Tiến hành dùng Attention Mechanism để tổng\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# hợp lại kết quả\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# x (B, num_patches, phi_dim)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m x, attn_weights = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# x = self._norm(x)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:1373\u001b[39m, in \u001b[36mMultiheadAttention.forward\u001b[39m\u001b[34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   1372\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1373\u001b[39m     attn_output, attn_output_weights = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1394\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\torch\\nn\\functional.py:6230\u001b[39m, in \u001b[36mmulti_head_attention_forward\u001b[39m\u001b[34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   6227\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m   6228\u001b[39m         in_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   6229\u001b[39m     ), \u001b[33m\"\u001b[39m\u001b[33muse_separate_proj_weight is False but in_proj_weight is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m6230\u001b[39m     q, k, v = \u001b[43m_in_projection_packed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6231\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\torch\\nn\\functional.py:5620\u001b[39m, in \u001b[36m_in_projection_packed\u001b[39m\u001b[34m(q, k, v, w, b)\u001b[39m\n\u001b[32m   5615\u001b[39m \u001b[38;5;66;03m# reshape to 3, E and not E, 3 is deliberate for better memory coalescing and keeping same order as chunk()\u001b[39;00m\n\u001b[32m   5616\u001b[39m proj = (\n\u001b[32m   5617\u001b[39m     \u001b[43mproj\u001b[49m\u001b[43m.\u001b[49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5618\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   5619\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m5620\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   5621\u001b[39m     .contiguous()\n\u001b[32m   5622\u001b[39m )\n\u001b[32m   5623\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m proj[\u001b[32m0\u001b[39m], proj[\u001b[32m1\u001b[39m], proj[\u001b[32m2\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Huấn luyện mô hình\u001b[39;00m\n\u001b[32m      2\u001b[39m trainer = Trainer(accelerator=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m, max_epochs=MAX_EPOCHS, logger=logger, callbacks=[early, best_checkpoint])\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\simulations\\implementations\\env\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:65\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[32m     64\u001b[39m         launcher.kill(_get_sigkill_signal())\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[43mexit\u001b[49m(\u001b[32m1\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m     68\u001b[39m     _interrupt(trainer, exception)\n",
      "\u001b[31mNameError\u001b[39m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "# Huấn luyện mô hình\n",
    "trainer = Trainer(accelerator=\"auto\", max_epochs=MAX_EPOCHS, logger=logger, callbacks=[early, best_checkpoint])\n",
    "trainer.fit(learner, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa0b03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "e:\\simulations\\implementations\\env\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'test_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 313/313 [00:06<00:00, 49.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.930400013923645     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     5.092170715332031     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.930400013923645    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    5.092170715332031    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test/loss': 5.092170715332031, 'test/acc': 0.930400013923645}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(learner, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0268a935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.2225, -4.2506,  1.1206, -4.2685, -1.6954,  4.0609,  1.6806, -3.7513,\n",
       "         -1.2111, -0.6855]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = solver.forward(learner.example_input_array, skip_avatar=True)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0987efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiến hành lưu lại mô hình, lưu phân rã các thành phần mô hình\n",
    "solver.save(f\"../database/{PROBLEM_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1f2783",
   "metadata": {},
   "source": [
    "### Thử khai thác tính chất OOP của solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a05ef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thử lấy một lớp khai thác\n",
    "instance, _ = solver.as_instance(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2438761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DigitExploiter(digit=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7383c14",
   "metadata": {},
   "source": [
    "### Thử load solver đã giải quyết"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f65a02",
   "metadata": {},
   "source": [
    "### Thử nghiệm nhận diện mẫu chưa đào tạo, tận dụng kết quả từ vector đại diện học được trong ArcFaceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453118aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.DigitClassifierLearner"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82ecc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 128)\n"
     ]
    }
   ],
   "source": [
    "protos = learner._specialized_space.W.detach().numpy().astype(\"float32\").T\n",
    "index = faiss.IndexFlatIP(PHI_DIM)\n",
    "index.add(protos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107002e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.0357275]]\n",
      "[[2]]\n"
     ]
    }
   ],
   "source": [
    "D, I = index.search(solver.forward(learner.example_input_array)[1].detach().numpy(), k=1)\n",
    "print(D)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cf8fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
