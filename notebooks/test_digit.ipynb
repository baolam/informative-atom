{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0794671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from fgi import *\n",
    "from torch import nn, empty, softmax, randn, cat\n",
    "from torch import optim, no_grad\n",
    "from torchmetrics import Accuracy\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5ad0895",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Digit:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27be6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationDigit(NonCodeProblem):\n",
    "    def __init__(self, _id, *args, **kwargs):\n",
    "        super().__init__(_id, *args, **kwargs)\n",
    "        self._r = ImageRepresent(img_shape=(1, 28, 28), patch_size=7, num_heads=1, phi_dim=128)\n",
    "        self._enhance = EnhanceRepresentUnit(phi_dim=128, dropout=0.2)\n",
    "        self._property = PropertyUnit(phi_dim=128, dropout=0.2)\n",
    "        self._specialized = nn.Linear(128, 10)\n",
    "\n",
    "        self._update_additional_infor()\n",
    "        \n",
    "    def forward(self, x, allow_cluster : bool = False,*args, **kwargs):\n",
    "        q1 = self._r(x)\n",
    "        q1 = self._enhance(q1)\n",
    "\n",
    "        q2 = self._property(q1)\n",
    "        q2 = self._specialized(q1 + q2)\n",
    "        \n",
    "        q2 = softmax(q2, dim = 1)\n",
    "        if allow_cluster:\n",
    "            return q2, self._enhance._memory(q1)\n",
    "        return q2\n",
    "\n",
    "    @property\n",
    "    def _as_object(self):\n",
    "        return Digit\n",
    "    \n",
    "    def recognize_unknown(self, x, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Lấy kết quả embedding nháp\n",
    "        \"\"\"\n",
    "        x = self._r(x)\n",
    "        x = self._enhance._memory(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d27cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitLearner(LightningLearner):\n",
    "    def __init__(self, problem, *args, **kwargs):\n",
    "        super().__init__(problem, *args, **kwargs)\n",
    "        self._loss_fn = nn.CrossEntropyLoss()\n",
    "        self._taccuracy = Accuracy(task='multiclass', num_classes=10)\n",
    "        self._vaccuracy = Accuracy(task='multiclass', num_classes=10)\n",
    "        self.example_input_array = randn((1, 1, 28, 28))\n",
    "    \n",
    "    def _aggerate_loss(self, y_hat, y, *args, **kwargs):\n",
    "        return self._loss_fn(y_hat, y)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # LR scheduler\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(self._optimizer, mode=\"min\", patience=3)\n",
    "        return { \"optimizer\" : self._optimizer, \"lr_scheduler\" : scheduler, \"monitor\" : \"val_loss\" }\n",
    "    \n",
    "    def training_step(self, batch, batch_idx, *args, **kwargs):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self._aggerate_loss(y_hat, y)\n",
    "        self._taccuracy.update(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log(\"train_acc\", self._taccuracy, prog_bar=True, on_step=True, on_epoch=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def on_test_batch_end(self, batch, batch_idx, dataloader_idx = 0):\n",
    "        lr = self.trainer.optimizers[0].param_groups[0]['lr']\n",
    "        self.log('end_lr', lr, logger=True, prog_bar=True, on_epoch=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx, *args, **kwargs):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self._aggerate_loss(y_hat, y)\n",
    "        self._vaccuracy.update(y_hat, y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_step=False, on_epoch=True, logger=True)\n",
    "        self.log(\"val_acc\", self._vaccuracy, prog_bar=True, on_step=False, on_epoch=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_end(self):\n",
    "        max_examples = 1000  # Giới hạn để tránh log quá nặng\n",
    "        collected = 0\n",
    "\n",
    "        all_images = []\n",
    "        all_labels = []\n",
    "        all_embeddings = []\n",
    "\n",
    "        self.eval()\n",
    "        with no_grad():\n",
    "            for batch in self.trainer.val_dataloaders:\n",
    "                x, y = batch\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "\n",
    "                # Encode ảnh thành vector đặc trưng (ví dụ: self._problem.encode)\n",
    "                embedding = self._problem.recognize_unknown(x)\n",
    "\n",
    "                all_images.append(x.cpu())\n",
    "                all_labels.append(y.cpu())\n",
    "                all_embeddings.append(embedding.cpu())\n",
    "\n",
    "                collected += x.size(0)\n",
    "                if collected >= max_examples:\n",
    "                    break  # Dừng sớm nếu vượt quá max_examples\n",
    "\n",
    "        # Nối lại và cắt đúng số lượng\n",
    "        all_images = cat(all_images, dim=0)[:max_examples]\n",
    "        all_labels = cat(all_labels, dim=0)[:max_examples]\n",
    "        all_embeddings = cat(all_embeddings, dim=0)[:max_examples]\n",
    "\n",
    "        # Ghi embedding lên TensorBoard\n",
    "        self.logger.experiment.add_embedding(\n",
    "            mat=all_embeddings,\n",
    "            metadata=[str(label.item()) for label in all_labels],\n",
    "            label_img=all_images,\n",
    "            global_step=self.global_step,\n",
    "            tag=\"final_embedding\"\n",
    "        )\n",
    "    \n",
    "    def test_step(self, batch, batch_idx, *args, **kwargs):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self._aggerate_loss(y_hat, y)\n",
    "        self._vaccuracy.update(y_hat, y)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, on_step=False, on_epoch=True, logger=True)\n",
    "        self.log(\"test_acc\", self._vaccuracy, prog_bar=True, on_step=False, on_epoch=True, logger=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f0cb668",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=32, shuffle=True, num_workers=7, persistent_workers=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=32, shuffle=False, num_workers=7, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a831ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = ClassificationDigit(\"digit_classification\")\n",
    "learner = DigitLearner(solver)\n",
    "for _id in learner.learnable.keys():\n",
    "    learner.learnable = (_id, True)\n",
    "logger = TensorBoardLogger(\"digit_problem\", name=\"exp\", log_graph=True)\n",
    "early = EarlyStopping(\"val_loss\", mode='min', patience=8, verbose=True)\n",
    "checkpoint = ModelCheckpoint(filename=\"best\", monitor=\"val_loss\", verbose=True, mode=\"min\")\n",
    "learner.compile(optim.SGD, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "100756c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10])\n",
      "tensor([[0.0797, 0.0840, 0.1123, 0.0880, 0.1262, 0.1077, 0.1108, 0.1400, 0.0960,\n",
      "         0.0553],\n",
      "        [0.0810, 0.0841, 0.1153, 0.0887, 0.1306, 0.1086, 0.1067, 0.1347, 0.0935,\n",
      "         0.0569],\n",
      "        [0.0804, 0.0878, 0.1111, 0.0882, 0.1338, 0.1077, 0.1087, 0.1318, 0.0952,\n",
      "         0.0552],\n",
      "        [0.0794, 0.0885, 0.1121, 0.0884, 0.1304, 0.1059, 0.1073, 0.1341, 0.0959,\n",
      "         0.0580],\n",
      "        [0.0807, 0.0852, 0.1167, 0.0891, 0.1323, 0.1045, 0.1091, 0.1332, 0.0950,\n",
      "         0.0542],\n",
      "        [0.0806, 0.0837, 0.1170, 0.0899, 0.1284, 0.1080, 0.1065, 0.1380, 0.0930,\n",
      "         0.0550],\n",
      "        [0.0788, 0.0847, 0.1142, 0.0871, 0.1320, 0.1083, 0.1106, 0.1336, 0.0941,\n",
      "         0.0567],\n",
      "        [0.0796, 0.0869, 0.1149, 0.0872, 0.1281, 0.1067, 0.1089, 0.1376, 0.0947,\n",
      "         0.0554],\n",
      "        [0.0782, 0.0834, 0.1137, 0.0904, 0.1293, 0.1083, 0.1070, 0.1385, 0.0948,\n",
      "         0.0565],\n",
      "        [0.0807, 0.0840, 0.1176, 0.0869, 0.1349, 0.1061, 0.1087, 0.1352, 0.0919,\n",
      "         0.0541],\n",
      "        [0.0778, 0.0862, 0.1155, 0.0895, 0.1291, 0.1103, 0.1066, 0.1339, 0.0941,\n",
      "         0.0570],\n",
      "        [0.0818, 0.0855, 0.1200, 0.0890, 0.1256, 0.1088, 0.1076, 0.1307, 0.0958,\n",
      "         0.0552],\n",
      "        [0.0807, 0.0876, 0.1132, 0.0912, 0.1261, 0.1062, 0.1067, 0.1363, 0.0958,\n",
      "         0.0562],\n",
      "        [0.0812, 0.0869, 0.1151, 0.0873, 0.1252, 0.1085, 0.1088, 0.1348, 0.0956,\n",
      "         0.0566],\n",
      "        [0.0805, 0.0852, 0.1154, 0.0882, 0.1296, 0.1087, 0.1091, 0.1330, 0.0956,\n",
      "         0.0547],\n",
      "        [0.0776, 0.0853, 0.1136, 0.0905, 0.1284, 0.1061, 0.1095, 0.1404, 0.0930,\n",
      "         0.0555],\n",
      "        [0.0795, 0.0852, 0.1157, 0.0899, 0.1322, 0.1061, 0.1084, 0.1324, 0.0958,\n",
      "         0.0549],\n",
      "        [0.0810, 0.0863, 0.1146, 0.0889, 0.1259, 0.1087, 0.1056, 0.1362, 0.0958,\n",
      "         0.0569],\n",
      "        [0.0779, 0.0861, 0.1166, 0.0899, 0.1316, 0.1086, 0.1077, 0.1324, 0.0934,\n",
      "         0.0559],\n",
      "        [0.0785, 0.0871, 0.1119, 0.0886, 0.1317, 0.1072, 0.1074, 0.1363, 0.0940,\n",
      "         0.0573],\n",
      "        [0.0812, 0.0862, 0.1133, 0.0869, 0.1279, 0.1092, 0.1099, 0.1373, 0.0921,\n",
      "         0.0561],\n",
      "        [0.0800, 0.0847, 0.1157, 0.0902, 0.1310, 0.1064, 0.1079, 0.1372, 0.0928,\n",
      "         0.0542],\n",
      "        [0.0796, 0.0861, 0.1134, 0.0896, 0.1282, 0.1088, 0.1102, 0.1349, 0.0935,\n",
      "         0.0558],\n",
      "        [0.0783, 0.0862, 0.1132, 0.0905, 0.1243, 0.1089, 0.1079, 0.1394, 0.0946,\n",
      "         0.0568],\n",
      "        [0.0802, 0.0873, 0.1156, 0.0879, 0.1265, 0.1066, 0.1050, 0.1358, 0.0992,\n",
      "         0.0558],\n",
      "        [0.0792, 0.0871, 0.1142, 0.0888, 0.1313, 0.1051, 0.1069, 0.1332, 0.0967,\n",
      "         0.0576],\n",
      "        [0.0792, 0.0855, 0.1156, 0.0898, 0.1289, 0.1055, 0.1078, 0.1377, 0.0925,\n",
      "         0.0575],\n",
      "        [0.0795, 0.0860, 0.1150, 0.0898, 0.1322, 0.1074, 0.1074, 0.1325, 0.0950,\n",
      "         0.0551],\n",
      "        [0.0779, 0.0852, 0.1152, 0.0891, 0.1315, 0.1072, 0.1063, 0.1375, 0.0949,\n",
      "         0.0553],\n",
      "        [0.0798, 0.0842, 0.1153, 0.0884, 0.1271, 0.1091, 0.1064, 0.1382, 0.0955,\n",
      "         0.0560],\n",
      "        [0.0783, 0.0840, 0.1170, 0.0881, 0.1291, 0.1078, 0.1089, 0.1353, 0.0959,\n",
      "         0.0555],\n",
      "        [0.0795, 0.0869, 0.1193, 0.0878, 0.1269, 0.1055, 0.1076, 0.1346, 0.0971,\n",
      "         0.0549]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = randn((32, 1, 28, 28))\n",
    "y = solver(x)\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e79bce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type                | Params | Mode  | In sizes | Out sizes\n",
      "----------------------------------------------------------------------------------\n",
      "0 | _problem   | ClassificationDigit | 109 K  | train | ?        | ?        \n",
      "1 | _loss_fn   | CrossEntropyLoss    | 0      | train | ?        | ?        \n",
      "2 | _taccuracy | MulticlassAccuracy  | 0      | train | ?        | ?        \n",
      "3 | _vaccuracy | MulticlassAccuracy  | 0      | train | ?        | ?        \n",
      "----------------------------------------------------------------------------------\n",
      "109 K     Trainable params\n",
      "0         Non-trainable params\n",
      "109 K     Total params\n",
      "0.437     Total estimated model params size (MB)\n",
      "21        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1875/1875 [01:08<00:00, 27.44it/s, v_num=2, train_loss_step=1.970, val_loss=2.040, val_acc=0.430, train_loss_epoch=2.180, train_acc_epoch=0.270]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 2.039\n",
      "Epoch 0, global step 1875: 'val_loss' reached 2.03914 (best 2.03914), saving model to 'digit_problem\\\\exp\\\\version_2\\\\checkpoints\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1875/1875 [00:45<00:00, 41.08it/s, v_num=2, train_loss_step=1.930, val_loss=1.920, val_acc=0.549, train_loss_epoch=1.960, train_acc_epoch=0.507]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.121 >= min_delta = 0.0. New best score: 1.919\n",
      "Epoch 1, global step 3750: 'val_loss' reached 1.91855 (best 1.91855), saving model to 'digit_problem\\\\exp\\\\version_2\\\\checkpoints\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1875/1875 [00:54<00:00, 34.18it/s, v_num=2, train_loss_step=1.780, val_loss=1.880, val_acc=0.586, train_loss_epoch=1.900, train_acc_epoch=0.563]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.041 >= min_delta = 0.0. New best score: 1.878\n",
      "Epoch 2, global step 5625: 'val_loss' reached 1.87782 (best 1.87782), saving model to 'digit_problem\\\\exp\\\\version_2\\\\checkpoints\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1875/1875 [00:54<00:00, 34.47it/s, v_num=2, train_loss_step=1.720, val_loss=1.880, val_acc=0.584, train_loss_epoch=1.880, train_acc_epoch=0.581]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 1.877\n",
      "Epoch 3, global step 7500: 'val_loss' reached 1.87669 (best 1.87669), saving model to 'digit_problem\\\\exp\\\\version_2\\\\checkpoints\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1875/1875 [00:53<00:00, 34.78it/s, v_num=2, train_loss_step=1.930, val_loss=1.860, val_acc=0.605, train_loss_epoch=1.870, train_acc_epoch=0.589]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.018 >= min_delta = 0.0. New best score: 1.859\n",
      "Epoch 4, global step 9375: 'val_loss' reached 1.85887 (best 1.85887), saving model to 'digit_problem\\\\exp\\\\version_2\\\\checkpoints\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1875/1875 [00:53<00:00, 34.91it/s, v_num=2, train_loss_step=1.860, val_loss=1.880, val_acc=0.586, train_loss_epoch=1.860, train_acc_epoch=0.604]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 11250: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1875/1875 [00:55<00:00, 33.79it/s, v_num=2, train_loss_step=1.840, val_loss=1.860, val_acc=0.606, train_loss_epoch=1.850, train_acc_epoch=0.613]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 1.856\n",
      "Epoch 6, global step 13125: 'val_loss' reached 1.85583 (best 1.85583), saving model to 'digit_problem\\\\exp\\\\version_2\\\\checkpoints\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1875/1875 [00:58<00:00, 32.07it/s, v_num=2, train_loss_step=1.730, val_loss=1.860, val_acc=0.599, train_loss_epoch=1.840, train_acc_epoch=0.621]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 15000: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1875/1875 [00:55<00:00, 33.65it/s, v_num=2, train_loss_step=1.880, val_loss=1.820, val_acc=0.640, train_loss_epoch=1.830, train_acc_epoch=0.631]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.034 >= min_delta = 0.0. New best score: 1.822\n",
      "Epoch 8, global step 16875: 'val_loss' reached 1.82169 (best 1.82169), saving model to 'digit_problem\\\\exp\\\\version_2\\\\checkpoints\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1875/1875 [00:55<00:00, 33.92it/s, v_num=2, train_loss_step=1.710, val_loss=1.810, val_acc=0.645, train_loss_epoch=1.820, train_acc_epoch=0.636]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.007 >= min_delta = 0.0. New best score: 1.815\n",
      "Epoch 9, global step 18750: 'val_loss' reached 1.81494 (best 1.81494), saving model to 'digit_problem\\\\exp\\\\version_2\\\\checkpoints\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1875/1875 [00:51<00:00, 36.26it/s, v_num=2, train_loss_step=1.740, val_loss=1.810, val_acc=0.648, train_loss_epoch=1.820, train_acc_epoch=0.645]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 1.813\n",
      "Epoch 10, global step 20625: 'val_loss' reached 1.81292 (best 1.81292), saving model to 'digit_problem\\\\exp\\\\version_2\\\\checkpoints\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 1875/1875 [00:52<00:00, 35.65it/s, v_num=2, train_loss_step=1.690, val_loss=1.820, val_acc=0.642, train_loss_epoch=1.810, train_acc_epoch=0.649]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 22500: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 1875/1875 [00:52<00:00, 35.62it/s, v_num=2, train_loss_step=1.780, val_loss=1.830, val_acc=0.627, train_loss_epoch=1.810, train_acc_epoch=0.655]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 24375: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 1875/1875 [00:57<00:00, 32.42it/s, v_num=2, train_loss_step=1.920, val_loss=1.790, val_acc=0.673, train_loss_epoch=1.800, train_acc_epoch=0.661]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.026 >= min_delta = 0.0. New best score: 1.787\n",
      "Epoch 13, global step 26250: 'val_loss' reached 1.78740 (best 1.78740), saving model to 'digit_problem\\\\exp\\\\version_2\\\\checkpoints\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1875/1875 [00:51<00:00, 36.41it/s, v_num=2, train_loss_step=1.930, val_loss=1.800, val_acc=0.662, train_loss_epoch=1.800, train_acc_epoch=0.664]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 28125: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 1875/1875 [00:51<00:00, 36.55it/s, v_num=2, train_loss_step=1.740, val_loss=1.780, val_acc=0.677, train_loss_epoch=1.790, train_acc_epoch=0.671]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 1.784\n",
      "Epoch 15, global step 30000: 'val_loss' reached 1.78387 (best 1.78387), saving model to 'digit_problem\\\\exp\\\\version_2\\\\checkpoints\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 1875/1875 [00:51<00:00, 36.23it/s, v_num=2, train_loss_step=1.900, val_loss=1.790, val_acc=0.674, train_loss_epoch=1.790, train_acc_epoch=0.673]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 31875: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 1875/1875 [00:49<00:00, 38.16it/s, v_num=2, train_loss_step=1.830, val_loss=1.790, val_acc=0.668, train_loss_epoch=1.780, train_acc_epoch=0.675]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 33750: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 1875/1875 [00:53<00:00, 35.11it/s, v_num=2, train_loss_step=1.790, val_loss=1.770, val_acc=0.689, train_loss_epoch=1.780, train_acc_epoch=0.678]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.011 >= min_delta = 0.0. New best score: 1.772\n",
      "Epoch 18, global step 35625: 'val_loss' reached 1.77246 (best 1.77246), saving model to 'digit_problem\\\\exp\\\\version_2\\\\checkpoints\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 1875/1875 [00:46<00:00, 40.08it/s, v_num=2, train_loss_step=1.720, val_loss=1.780, val_acc=0.680, train_loss_epoch=1.780, train_acc_epoch=0.680]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 37500: 'val_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 1875/1875 [00:46<00:00, 40.06it/s, v_num=2, train_loss_step=1.720, val_loss=1.780, val_acc=0.680, train_loss_epoch=1.780, train_acc_epoch=0.680]\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(accelerator=\"auto\", max_epochs=20, logger=logger, callbacks=[early, checkpoint])\n",
    "trainer.fit(learner, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46bcaa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba996c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def release_gpu():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc452074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0954, -0.0140,  0.0084,  0.0224,  0.1769,  0.0653,  0.0523,  0.0893,\n",
      "         -0.0787, -0.0988,  0.1298,  0.0851,  0.0388,  0.0333,  0.0825,  0.0567,\n",
      "          0.0262, -0.0435,  0.0611,  0.0188, -0.0274,  0.1573,  0.1744,  0.0270,\n",
      "          0.0371, -0.0164, -0.0905, -0.0749,  0.0207, -0.0882,  0.0025,  0.0393,\n",
      "         -0.1258, -0.1198, -0.0268,  0.0048, -0.0498,  0.0643,  0.1373, -0.0552,\n",
      "         -0.0726,  0.1049,  0.0723, -0.0069,  0.1080,  0.0289, -0.0128, -0.0730,\n",
      "          0.0257, -0.1121,  0.1582, -0.1215, -0.0264, -0.1740,  0.0367,  0.0222,\n",
      "         -0.0128, -0.0140,  0.0477,  0.0984, -0.0434,  0.0044, -0.0108,  0.0329,\n",
      "          0.0676, -0.0560,  0.0680, -0.0491, -0.0177,  0.1825, -0.0736,  0.0491,\n",
      "          0.1740, -0.0237,  0.0150, -0.0125, -0.0224,  0.0714,  0.0304, -0.0910,\n",
      "          0.0946, -0.0120, -0.0351,  0.0288, -0.1054,  0.1121,  0.2064,  0.0781,\n",
      "         -0.0396,  0.1400, -0.0542,  0.0227,  0.0781, -0.0866,  0.0435,  0.0323,\n",
      "         -0.0536,  0.1005,  0.1164, -0.0234, -0.0568, -0.0782, -0.0106, -0.0137,\n",
      "         -0.0609,  0.2266, -0.1406,  0.0843, -0.0400,  0.0645, -0.0061,  0.0565,\n",
      "         -0.0728, -0.1052, -0.1086, -0.2004, -0.0803, -0.1522, -0.0644, -0.0288,\n",
      "         -0.0074, -0.1650,  0.0563,  0.1969, -0.0906, -0.0141,  0.2534,  0.0563]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Thử nghiệm, \n",
    "x = randn((1, 1, 28, 28))\n",
    "y = solver.recognize_unknown(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd524f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.8497],\n",
       "        [-0.1649],\n",
       "        [-0.6671],\n",
       "        [-0.7005],\n",
       "        [-1.1308],\n",
       "        [-0.8200],\n",
       "        [ 1.0125],\n",
       "        [-0.0162],\n",
       "        [-0.7855],\n",
       "        [-0.3339],\n",
       "        [-0.6511],\n",
       "        [ 0.7315],\n",
       "        [ 0.8304],\n",
       "        [ 0.9673],\n",
       "        [-0.4510],\n",
       "        [-0.8589],\n",
       "        [ 0.5375],\n",
       "        [-0.5861],\n",
       "        [-0.2845],\n",
       "        [-1.0333],\n",
       "        [-0.4609],\n",
       "        [ 0.9132],\n",
       "        [ 0.2548],\n",
       "        [-1.0764],\n",
       "        [ 0.8823],\n",
       "        [-0.2858],\n",
       "        [-0.7323],\n",
       "        [ 1.0920],\n",
       "        [ 0.6885],\n",
       "        [-0.5932],\n",
       "        [ 1.0859],\n",
       "        [-0.5217],\n",
       "        [-0.1651],\n",
       "        [-0.2630],\n",
       "        [ 0.3265],\n",
       "        [-0.6915],\n",
       "        [-0.4359],\n",
       "        [ 0.0079],\n",
       "        [-0.5314],\n",
       "        [-0.5768],\n",
       "        [-0.9093],\n",
       "        [-0.2034],\n",
       "        [ 0.3921],\n",
       "        [-0.6015],\n",
       "        [-0.1419],\n",
       "        [-0.4693],\n",
       "        [-0.5811],\n",
       "        [-0.0611],\n",
       "        [-0.2193],\n",
       "        [-0.1723],\n",
       "        [ 0.7413],\n",
       "        [-0.0549],\n",
       "        [ 0.6323],\n",
       "        [-0.0216],\n",
       "        [-0.4710],\n",
       "        [-0.6276],\n",
       "        [-0.6576],\n",
       "        [-0.8176],\n",
       "        [-0.2137],\n",
       "        [-1.2024],\n",
       "        [ 0.6532],\n",
       "        [ 0.7392],\n",
       "        [-0.8759],\n",
       "        [ 0.2570],\n",
       "        [-0.3267],\n",
       "        [ 0.8563],\n",
       "        [ 0.7394],\n",
       "        [-0.3588],\n",
       "        [ 0.2854],\n",
       "        [-0.5964],\n",
       "        [ 0.0859],\n",
       "        [-0.4601],\n",
       "        [-0.0437],\n",
       "        [ 1.0037],\n",
       "        [ 0.7875],\n",
       "        [-0.2623],\n",
       "        [ 0.6079],\n",
       "        [-0.0896],\n",
       "        [ 1.0792],\n",
       "        [ 0.6647],\n",
       "        [ 0.0099],\n",
       "        [ 1.0731],\n",
       "        [-0.8451],\n",
       "        [-0.7118],\n",
       "        [-0.1478],\n",
       "        [-0.8194],\n",
       "        [ 0.8339],\n",
       "        [ 0.1539],\n",
       "        [ 0.5093],\n",
       "        [-0.0093],\n",
       "        [-0.2762],\n",
       "        [-0.2615],\n",
       "        [ 0.8966],\n",
       "        [ 0.0198],\n",
       "        [ 0.7789],\n",
       "        [ 0.1924],\n",
       "        [ 0.1191],\n",
       "        [-1.0478],\n",
       "        [ 0.1616],\n",
       "        [ 0.7407],\n",
       "        [-0.1626],\n",
       "        [-1.0126],\n",
       "        [-0.6821],\n",
       "        [ 1.0731],\n",
       "        [-0.4896],\n",
       "        [ 0.3100],\n",
       "        [ 0.0665],\n",
       "        [ 0.5189],\n",
       "        [-0.2094],\n",
       "        [-0.4190],\n",
       "        [ 1.0549],\n",
       "        [-0.3572],\n",
       "        [ 0.0982],\n",
       "        [-0.9312],\n",
       "        [-0.1033],\n",
       "        [-0.0220],\n",
       "        [-0.0678],\n",
       "        [-0.3758],\n",
       "        [ 0.8116],\n",
       "        [-0.1614],\n",
       "        [-0.2413],\n",
       "        [ 0.6461],\n",
       "        [-1.1053],\n",
       "        [ 0.3574],\n",
       "        [ 0.9707],\n",
       "        [ 0.0346],\n",
       "        [ 0.1778],\n",
       "        [ 0.8963]], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver._property._projection.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3efe5a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.1737e-05, 1.2643e-07, 1.2497e-11, 9.3249e-01, 1.0302e-02, 1.7257e-11,\n",
       "         1.2375e-09, 1.3433e-38, 5.7184e-02, 1.3740e-31]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dfddaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = solver(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3594bc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c90cb6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9325, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c05b738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 313/313 [00:05<00:00, 59.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          end_lr           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10000026226043701    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.680400013923645     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.7803601026535034     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         end_lr          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10000026226043701   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.680400013923645    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.7803601026535034    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.7803601026535034,\n",
       "  'test_acc': 0.680400013923645,\n",
       "  'end_lr': 0.10000026226043701}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(learner, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1edf6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
