{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "645b3b65",
   "metadata": {},
   "source": [
    "### Thử nghiệm bộ dữ liệu phong cảnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ecc9214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Các thư viện cần dùng cho dự án\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import random\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "from fgi import *\n",
    "from torch import nn, optim\n",
    "from torchmetrics import Accuracy\n",
    "from pytorch_metric_learning import losses, miners, samplers\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cef81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Các đánh giá hành vi\n",
    "IMG_SHAPE = (3, 256, 256) # C, H, W (ảnh xám mặc định)\n",
    "CANNY_SHAPE = (1, 256, 256) # Kích thước ảnh qua tách cạnh\n",
    "IMG_SIZE = (IMG_SHAPE[1], IMG_SHAPE[2])\n",
    "PHI_DIM = 128\n",
    "DEFAULT_LR = 0.002\n",
    "MAX_EXAMPLES = 1000 # Dùng cho embedding\n",
    "NORMALIZE_IMAGE = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n",
    "NUM_WORKERS = 7\n",
    "BATCH_SIZE = 32\n",
    "STORAGE_DATA = \"../data/landscape\"\n",
    "OPTIONS = os.listdir(STORAGE_DATA + \"/train\")\n",
    "NUM_CLASSES = len(OPTIONS)\n",
    "PROBLEM_ID = \"landscape_classifier\"\n",
    "EXPERIMENT_TENSORBOARD_NAME = PROBLEM_ID\n",
    "EXPRIMENT_TENSORBOARD_PATH = \"../experiment/\"\n",
    "SEED_CODE = 131006 # Random id dùng cho sinh dữ liệu\n",
    "TRAIN_SIZE = 0.8 # 80% dữ liệu train sẽ được đem đi đào tạo, 20% cho validation\n",
    "NUM_SAMPLE_PER_CLASS = 4 # Số sample mỗi label dành cho học không gian embedding\n",
    "DROPOUT = 0.2 # Công dụng regularier, cấu hình cho nn.Dropout\n",
    "TRIPLER_MARGIN = 2.0 # Độ khác biệt tối thiểu giữa anchor và positive, dùng cho biệt hoá không gian embedding\n",
    "STRATEGY_ANCHOR_POSITIVE = \"hard\"\n",
    "DEVICE = \"cpu\"\n",
    "PATIENCE = 4 # Số lượt đợi không cải thiện\n",
    "LAMBDA_CLASSIFY = 1. # Trọng số đánh giá tầm quan trọng mục tiêu phân loại\n",
    "LAMBDA_EMBEDDING = 1. # Trọng số đánh giá tầm quan trọng mục tiêu biệt hoá không gian\n",
    "ILLUSTRATION_EXAMPLES = 1000 # Giới hạn số mẫu dùng cho show projector trong tensorboard\n",
    "MAX_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eb5d2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
      "(256, 256)\n"
     ]
    }
   ],
   "source": [
    "# In thử các lớp\n",
    "print(OPTIONS)\n",
    "print(IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fc24756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cấu hình pytorch đảm bảo thí nghiệm\n",
    "torch.manual_seed(SEED_CODE)\n",
    "random.seed(SEED_CODE)\n",
    "np.random.seed(SEED_CODE)\n",
    "torch.cuda.manual_seed(SEED_CODE)\n",
    "torch.cuda.manual_seed_all(SEED_CODE)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7fc60c",
   "metadata": {},
   "source": [
    "### Chuẩn bị dữ liệu huấn luyện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e426521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(IMG_SIZE),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(*NORMALIZE_IMAGE)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a42e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = torchvision.datasets.ImageFolder(STORAGE_DATA + \"/train\", transform=train_transform)\n",
    "\n",
    "# Chia tập train và validation\n",
    "train_size = int(len(full_dataset) * TRAIN_SIZE)\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Lấy bộ dữ liệu test\n",
    "test_dataset = torchvision.datasets.ImageFolder(STORAGE_DATA + \"/test\", transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e1d5040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước toàn bộ dữ liệu đào tạo: 14034\n",
      "Kích thước dữ liệu cho training: 11227\n",
      "Kích thước dữ liệu cho validation: 2807\n",
      "Kích thước dữ liệu cho test: 3000\n"
     ]
    }
   ],
   "source": [
    "# In thử thông tin bộ dữ liệu\n",
    "print(f\"Kích thước toàn bộ dữ liệu đào tạo: {len(full_dataset)}\")\n",
    "print(f\"Kích thước dữ liệu cho training: {train_size}\")\n",
    "print(f\"Kích thước dữ liệu cho validation: {val_size}\")\n",
    "print(f\"Kích thước dữ liệu cho test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14188c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiến hành tạo DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, persistent_workers=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, persistent_workers=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9e3ea2",
   "metadata": {},
   "source": [
    "### Kiến trúc mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9e40c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lớp hành vi của vấn đề\n",
    "class LandscapeClassifier(NonCodeProblem):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(PROBLEM_ID, *args, **kwargs)\n",
    "        self._represent = RepresentLayer([\n",
    "            ImageRepresent(img_shape=IMG_SHAPE, patch_size=16, num_heads=1, phi_dim=PHI_DIM),\n",
    "            ImageRepresent(img_shape=IMG_SHAPE, patch_size=16, num_heads=1, phi_dim=PHI_DIM)\n",
    "        ], output_dim=PHI_DIM)\n",
    "        self._combine_repr = CoRepresentLayer(\n",
    "            [ CoRepresentUnit(2, phi_dim=PHI_DIM) ]\n",
    "        )\n",
    "        self._property = PropertyUnit(phi_dim=PHI_DIM)\n",
    "        self._task = ChooseOptions(1, options=OPTIONS, property_name=\"landscape\", phi_dim=PHI_DIM)\n",
    "    \n",
    "    def recognize_unknown(self, x, *args, **kwargs):\n",
    "        x = self._represent(x)\n",
    "        x = self._combine_repr(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x, skip_avatar : bool = False, *args, **kwargs):\n",
    "        x = self._represent(x)\n",
    "        x = self._combine_repr(x)\n",
    "\n",
    "        q = self._property(x)\n",
    "        q = self._task(x + q)\n",
    "\n",
    "        if skip_avatar:\n",
    "            return q\n",
    "        \n",
    "        return q, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63570c18",
   "metadata": {},
   "source": [
    "### Cấu hình huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b9529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viết lớp Learner dành riêng cho việc học đào tạo vấn đề\n",
    "class LandscapeClassifierLearner(LightningLearner):\n",
    "    def __init__(self, problem, *args, **kwargs):\n",
    "        super().__init__(problem, *args, **kwargs)\n",
    "        self._classify = nn.CrossEntropyLoss()\n",
    "        self._specialized_space = losses.ArcFaceLoss(num_classes=NUM_CLASSES, embedding_size=PHI_DIM, margin=TRIPLER_MARGIN)\n",
    "        self._train_accuracy = Accuracy(task=\"multiclass\", num_classes=NUM_CLASSES)\n",
    "        self._val_accuracy = Accuracy(task=\"multiclass\", num_classes=NUM_CLASSES)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # Kết hợp thêm chiến lược scheduler\n",
    "        optimizer = optim.AdamW(self._problem.parameters(), lr=DEFAULT_LR)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=PATIENCE - 2)\n",
    "        return { \"optimizer\" : optimizer, \"lr_scheduler\" : scheduler, \"monitor\" : \"val/loss\" }\n",
    "\n",
    "    def training_step(self, batch, batch_idx, *args, **kwargs):\n",
    "        x, y = batch\n",
    "        y_predicted = self(x)\n",
    "\n",
    "        loss, ce, triplet = self._aggerate_loss(y_predicted, y)\n",
    "        self._train_accuracy.update(y_predicted[0], y)\n",
    "        \n",
    "        self.log(\"train/loss\", loss, prog_bar=True, logger=True, on_epoch=True, on_step=True)\n",
    "        self.log(\"train/ce\", ce, prog_bar=True, logger=True, on_epoch=True)\n",
    "        self.log(\"train/triplet\", triplet, prog_bar=True, logger=True, on_epoch=True)\n",
    "        self.log(\"train/acc\", self._train_accuracy, prog_bar=True, on_epoch=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx, *args, **kwargs):\n",
    "        x, y = batch\n",
    "        y_predicted = self(x)\n",
    "\n",
    "        loss, ce, triplet = self._aggerate_loss(y_predicted, y)\n",
    "        self._val_accuracy.update(y_predicted[0], y)\n",
    "\n",
    "        self.log(\"val/loss\", loss, prog_bar=True, logger=True, on_epoch=True)\n",
    "        self.log(\"val/acc\", self._val_accuracy, prog_bar=True, logger=True, on_epoch=True)\n",
    "        self.log(\"val/ce\", ce, prog_bar=True, logger=True, on_epoch=True)\n",
    "        self.log(\"val/triplet\", triplet, prog_bar=True, logger=True, on_epoch=True)\n",
    "\n",
    "    def on_train_batch_end(self, outputs, batch, batch_idx):\n",
    "        lr = self.trainer.optimizers[0].param_groups[0]['lr']\n",
    "        self.log(\"lr\", lr, logger=True, on_epoch=True)\n",
    "\n",
    "    def _aggerate_loss(self, y_predicted, y, *args, **kwargs):\n",
    "        y_hat, emb = y_predicted\n",
    "\n",
    "        ce = self._classify(y_hat, y)\n",
    "        triplet = self._specialized_space(emb, y)\n",
    "\n",
    "        loss = LAMBDA_CLASSIFY * ce + LAMBDA_EMBEDDING * triplet\n",
    "\n",
    "        return loss, ce, triplet\n",
    "    \n",
    "    def test_step(self, batch, *args, **kwargs):\n",
    "        x, y = batch\n",
    "        y_predicted = self(x)\n",
    "\n",
    "        loss, __, __ = self._aggerate_loss(y_predicted, y)\n",
    "        self._val_accuracy.update(y_predicted[0], y)\n",
    "\n",
    "        self.log(\"test/loss\", loss, prog_bar=True, on_epoch=True, logger=True)\n",
    "        self.log(\"test/acc\", self._val_accuracy, prog_bar=True, logger=True, on_epoch=True)\n",
    "    \n",
    "    def _get_embedding(self, iterators):\n",
    "        # Hiển thị thử embedding\n",
    "        collected = 0\n",
    "\n",
    "        all_labels = []\n",
    "        all_embeds = []\n",
    "\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in iterators:\n",
    "                x, y = batch\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "\n",
    "                # Encode ảnh thành vector đặc trưng (ví dụ: self._problem.encode)\n",
    "                embedding = self._problem.recognize_unknown(x)\n",
    "\n",
    "                # all_imgs.append(x.cpu())\n",
    "                all_labels.append(y.cpu())\n",
    "                all_embeds.append(embedding.cpu())\n",
    "\n",
    "                collected += x.size(0)\n",
    "                if collected >= ILLUSTRATION_EXAMPLES:\n",
    "                    break  # Dừng sớm nếu vượt quá max_examples\n",
    "        \n",
    "        # all_imgs = torch.cat(all_imgs, dim=0)[:ILLUSTRATION_EXAMPLES]\n",
    "        all_labels = torch.cat(all_labels, dim=0)[:ILLUSTRATION_EXAMPLES]\n",
    "        all_embeds = torch.cat(all_embeds, dim=0)[:ILLUSTRATION_EXAMPLES]\n",
    "\n",
    "        return all_labels, all_embeds\n",
    "\n",
    "    def on_train_end(self):\n",
    "        all_labels, all_embeds = self._get_embedding(self.trainer.val_dataloaders)\n",
    "        self.logger.experiment.add_embedding(\n",
    "            mat=all_embeds,\n",
    "            metadata=[str(label.item()) for label in all_labels],\n",
    "            global_step=self.global_step,\n",
    "            \n",
    "            tag=\"train/embedding\"\n",
    "        )\n",
    "\n",
    "    def on_test_end(self):\n",
    "        all_labels, all_embeds = self._get_embedding(self.trainer.test_dataloaders)\n",
    "        self.logger.experiment.add_embedding(\n",
    "            mat=all_embeds,\n",
    "            metadata=[str(label.item()) for label in all_labels],\n",
    "            global_step=self.global_step,\n",
    "            tag=\"test/embedding\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a721ab",
   "metadata": {},
   "source": [
    "### Phối hợp các Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "271ead1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'LandscapeClassifier',\n",
       " 'default_exploiter': None,\n",
       " 'call_update': True,\n",
       " 'layers': ['_combine_repr', '_represent'],\n",
       " 'units': ['0d8d303c-a03a-45a5-aefa-ac65193eea55',\n",
       "  '12e5bda7-4f2f-48b5-9075-137e8697a6ee',\n",
       "  '44205768-2097-4941-b91c-6173c5565207',\n",
       "  '48250f0e-e323-408c-855d-ab58c6ba7807',\n",
       "  '30289e13-9f29-4388-8559-317c39d30720'],\n",
       " 'properties': ['landscape']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Khởi tạo bộ giải quyết vấn đề\n",
    "solver = LandscapeClassifier()\n",
    "solver.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1e80ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo bộ học\n",
    "learner = LandscapeClassifierLearner(solver)\n",
    "learner.compile()\n",
    "# Vẽ đồ thị lan truyền\n",
    "learner.example_input_array = torch.randn(1, *IMG_SHAPE, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e7da4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.2007, 0.0642, 0.2203, 0.0598, 0.0201, 0.0890],\n",
      "        [0.1982, 0.0670, 0.2209, 0.0738, 0.0112, 0.0885],\n",
      "        [0.1960, 0.0681, 0.2140, 0.0687, 0.0174, 0.0934],\n",
      "        [0.1982, 0.0681, 0.2185, 0.0673, 0.0132, 0.0880],\n",
      "        [0.1962, 0.0639, 0.2138, 0.0729, 0.0099, 0.0853],\n",
      "        [0.1939, 0.0675, 0.2177, 0.0737, 0.0131, 0.0860],\n",
      "        [0.1961, 0.0675, 0.2152, 0.0724, 0.0177, 0.0877],\n",
      "        [0.2005, 0.0722, 0.2253, 0.0737, 0.0208, 0.0879],\n",
      "        [0.1965, 0.0646, 0.2153, 0.0658, 0.0111, 0.0940],\n",
      "        [0.1952, 0.0695, 0.2167, 0.0615, 0.0138, 0.0920],\n",
      "        [0.1983, 0.0680, 0.2208, 0.0689, 0.0154, 0.0918],\n",
      "        [0.2028, 0.0664, 0.2166, 0.0686, 0.0102, 0.0941],\n",
      "        [0.2028, 0.0709, 0.2173, 0.0680, 0.0102, 0.0852],\n",
      "        [0.1965, 0.0715, 0.2200, 0.0725, 0.0226, 0.0925],\n",
      "        [0.2037, 0.0668, 0.2157, 0.0703, 0.0124, 0.0899],\n",
      "        [0.2035, 0.0700, 0.2191, 0.0711, 0.0088, 0.0947],\n",
      "        [0.2036, 0.0677, 0.2211, 0.0711, 0.0154, 0.0858],\n",
      "        [0.2006, 0.0666, 0.2182, 0.0616, 0.0124, 0.0887],\n",
      "        [0.1982, 0.0696, 0.2200, 0.0670, 0.0169, 0.0890],\n",
      "        [0.1948, 0.0689, 0.2168, 0.0674, 0.0184, 0.0871],\n",
      "        [0.2007, 0.0663, 0.2183, 0.0708, 0.0194, 0.0872],\n",
      "        [0.2036, 0.0742, 0.2234, 0.0701, 0.0153, 0.0915],\n",
      "        [0.2006, 0.0704, 0.2178, 0.0684, 0.0168, 0.0878],\n",
      "        [0.1967, 0.0651, 0.2197, 0.0677, 0.0109, 0.0954],\n",
      "        [0.2000, 0.0650, 0.2175, 0.0674, 0.0093, 0.0917],\n",
      "        [0.1985, 0.0673, 0.2204, 0.0702, 0.0169, 0.0890],\n",
      "        [0.1973, 0.0716, 0.2170, 0.0667, 0.0114, 0.0875],\n",
      "        [0.1979, 0.0687, 0.2207, 0.0698, 0.0179, 0.0888],\n",
      "        [0.1953, 0.0618, 0.2151, 0.0685, 0.0126, 0.0901],\n",
      "        [0.1929, 0.0657, 0.2160, 0.0619, 0.0120, 0.0928],\n",
      "        [0.1954, 0.0730, 0.2196, 0.0713, 0.0160, 0.0822],\n",
      "        [0.1954, 0.0633, 0.2138, 0.0680, 0.0077, 0.0929]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.0823,  0.0148,  0.0167,  ..., -0.0958, -0.0366,  0.0036],\n",
      "        [ 0.0816,  0.0267,  0.0194,  ..., -0.0997, -0.0559, -0.0088],\n",
      "        [ 0.0912,  0.0220,  0.0145,  ..., -0.1081, -0.0497, -0.0024],\n",
      "        ...,\n",
      "        [ 0.0845,  0.0164,  0.0211,  ..., -0.1092, -0.0433, -0.0002],\n",
      "        [ 0.0897,  0.0169,  0.0158,  ..., -0.0987, -0.0532, -0.0110],\n",
      "        [ 0.0843,  0.0238,  0.0221,  ..., -0.1029, -0.0519, -0.0051]],\n",
      "       grad_fn=<AddBackward0>))\n"
     ]
    }
   ],
   "source": [
    "# Thử hiển thị và chạy thử solver\n",
    "y_predicted = solver(torch.randn(32, *IMG_SHAPE))\n",
    "print(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00f5d56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Thử in kích thước loader\n",
    "# imgs, labels = next(iter(train_loader))\n",
    "# print(imgs.shape)\n",
    "# y_hat = solver(imgs)\n",
    "# print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16c7215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cấu hình logger, callbacks\n",
    "logger = TensorBoardLogger(EXPRIMENT_TENSORBOARD_PATH, EXPERIMENT_TENSORBOARD_NAME, log_graph=False)\n",
    "early = EarlyStopping(\"val/loss\", patience=PATIENCE, verbose=True)\n",
    "best_checkpoint = ModelCheckpoint(dirpath=f\"../database/{PROBLEM_ID}\", filename=\"best\", monitor=\"val/loss\", verbose=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad96c02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "e:\\simulations\\implementations\\env\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:658: Checkpoint directory E:\\simulations\\implementations\\database\\landscape_classifier exists and is not empty.\n",
      "\n",
      "  | Name               | Type                | Params | Mode  | In sizes | Out sizes\n",
      "------------------------------------------------------------------------------------------\n",
      "0 | _problem           | LandscapeClassifier | 429 K  | train | ?        | ?        \n",
      "1 | _classify          | CrossEntropyLoss    | 0      | train | ?        | ?        \n",
      "2 | _specialized_space | ArcFaceLoss         | 768    | train | ?        | ?        \n",
      "3 | _train_accuracy    | MulticlassAccuracy  | 0      | train | ?        | ?        \n",
      "4 | _val_accuracy      | MulticlassAccuracy  | 0      | train | ?        | ?        \n",
      "------------------------------------------------------------------------------------------\n",
      "429 K     Trainable params\n",
      "0         Non-trainable params\n",
      "429 K     Total params\n",
      "1.719     Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 351/351 [02:12<00:00,  2.65it/s, v_num=0, train/loss_step=5.690, train/ce_step=1.780, train/triplet_step=3.910, val/loss=5.720, val/acc=0.174, val/ce=1.800, val/triplet=3.920, train/loss_epoch=8.710, train/ce_epoch=3.950, train/triplet_epoch=4.760, train/acc_epoch=0.171]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved. New best score: 5.718\n",
      "Epoch 0, global step 351: 'val/loss' reached 5.71845 (best 5.71845), saving model to 'E:\\\\simulations\\\\implementations\\\\database\\\\landscape_classifier\\\\best-v2.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 351/351 [02:03<00:00,  2.84it/s, v_num=0, train/loss_step=5.700, train/ce_step=1.770, train/triplet_step=3.920, val/loss=5.710, val/acc=0.174, val/ce=1.790, val/triplet=3.910, train/loss_epoch=5.760, train/ce_epoch=1.800, train/triplet_epoch=3.970, train/acc_epoch=0.169]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.012 >= min_delta = 0.0. New best score: 5.706\n",
      "Epoch 1, global step 702: 'val/loss' reached 5.70626 (best 5.70626), saving model to 'E:\\\\simulations\\\\implementations\\\\database\\\\landscape_classifier\\\\best-v2.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 351/351 [02:10<00:00,  2.69it/s, v_num=0, train/loss_step=5.800, train/ce_step=1.790, train/triplet_step=4.000, val/loss=5.740, val/acc=0.175, val/ce=1.800, val/triplet=3.940, train/loss_epoch=5.760, train/ce_epoch=1.800, train/triplet_epoch=3.960, train/acc_epoch=0.174]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 1053: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 351/351 [02:32<00:00,  2.30it/s, v_num=0, train/loss_step=5.750, train/ce_step=1.770, train/triplet_step=3.980, val/loss=5.720, val/acc=0.160, val/ce=1.810, val/triplet=3.910, train/loss_epoch=5.730, train/ce_epoch=1.800, train/triplet_epoch=3.930, train/acc_epoch=0.170]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 1404: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 351/351 [02:25<00:00,  2.42it/s, v_num=0, train/loss_step=5.830, train/ce_step=1.790, train/triplet_step=4.040, val/loss=5.720, val/acc=0.160, val/ce=1.790, val/triplet=3.930, train/loss_epoch=5.730, train/ce_epoch=1.790, train/triplet_epoch=3.930, train/acc_epoch=0.172]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 1755: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 351/351 [02:50<00:00,  2.06it/s, v_num=0, train/loss_step=5.650, train/ce_step=1.800, train/triplet_step=3.850, val/loss=5.660, val/acc=0.174, val/ce=1.790, val/triplet=3.870, train/loss_epoch=5.650, train/ce_epoch=1.790, train/triplet_epoch=3.860, train/acc_epoch=0.180]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.049 >= min_delta = 0.0. New best score: 5.658\n",
      "Epoch 5, global step 2106: 'val/loss' reached 5.65774 (best 5.65774), saving model to 'E:\\\\simulations\\\\implementations\\\\database\\\\landscape_classifier\\\\best-v2.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 351/351 [03:17<00:00,  1.78it/s, v_num=0, train/loss_step=5.640, train/ce_step=1.780, train/triplet_step=3.850, val/loss=5.650, val/acc=0.175, val/ce=1.790, val/triplet=3.860, train/loss_epoch=5.650, train/ce_epoch=1.790, train/triplet_epoch=3.860, train/acc_epoch=0.179]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.003 >= min_delta = 0.0. New best score: 5.654\n",
      "Epoch 6, global step 2457: 'val/loss' reached 5.65433 (best 5.65433), saving model to 'E:\\\\simulations\\\\implementations\\\\database\\\\landscape_classifier\\\\best-v2.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 351/351 [02:48<00:00,  2.08it/s, v_num=0, train/loss_step=5.600, train/ce_step=1.780, train/triplet_step=3.830, val/loss=5.650, val/acc=0.175, val/ce=1.790, val/triplet=3.860, train/loss_epoch=5.650, train/ce_epoch=1.790, train/triplet_epoch=3.860, train/acc_epoch=0.176]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.007 >= min_delta = 0.0. New best score: 5.647\n",
      "Epoch 7, global step 2808: 'val/loss' reached 5.64706 (best 5.64706), saving model to 'E:\\\\simulations\\\\implementations\\\\database\\\\landscape_classifier\\\\best-v2.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 351/351 [03:11<00:00,  1.83it/s, v_num=0, train/loss_step=5.580, train/ce_step=1.790, train/triplet_step=3.790, val/loss=5.660, val/acc=0.175, val/ce=1.790, val/triplet=3.870, train/loss_epoch=5.650, train/ce_epoch=1.790, train/triplet_epoch=3.860, train/acc_epoch=0.178]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 3159: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 351/351 [02:36<00:00,  2.25it/s, v_num=0, train/loss_step=5.740, train/ce_step=1.810, train/triplet_step=3.930, val/loss=5.680, val/acc=0.175, val/ce=1.790, val/triplet=3.880, train/loss_epoch=5.650, train/ce_epoch=1.790, train/triplet_epoch=3.860, train/acc_epoch=0.174]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 3510: 'val/loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 351/351 [02:36<00:00,  2.25it/s, v_num=0, train/loss_step=5.740, train/ce_step=1.810, train/triplet_step=3.930, val/loss=5.680, val/acc=0.175, val/ce=1.790, val/triplet=3.880, train/loss_epoch=5.650, train/ce_epoch=1.790, train/triplet_epoch=3.860, train/acc_epoch=0.174]\n"
     ]
    }
   ],
   "source": [
    "# Huấn luyện mô hình\n",
    "trainer = Trainer(accelerator=\"auto\", max_epochs=MAX_EPOCHS, logger=logger, callbacks=[early, best_checkpoint])\n",
    "trainer.fit(learner, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c649edcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
