{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "645b3b65",
   "metadata": {},
   "source": [
    "### Thử nghiệm bộ dữ liệu phong cảnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecc9214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Các thư viện cần dùng cho dự án\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import random\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "from fgi import *\n",
    "from torch import nn, optim\n",
    "from torchmetrics import Accuracy\n",
    "from pytorch_metric_learning import losses, miners, samplers\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cef81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Các đánh giá hành vi\n",
    "IMG_SHAPE = (3, 256, 256) # C, H, W (ảnh xám mặc định)\n",
    "CANNY_SHAPE = (1, 256, 256) # Kích thước ảnh qua tách cạnh\n",
    "IMG_SIZE = (IMG_SHAPE[1], IMG_SHAPE[2])\n",
    "PHI_DIM = 128\n",
    "DEFAULT_LR = 0.002\n",
    "MAX_EXAMPLES = 1000 # Dùng cho embedding\n",
    "NORMALIZE_IMAGE = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n",
    "NUM_WORKERS = 7\n",
    "BATCH_SIZE = 32\n",
    "STORAGE_DATA = \"../data/landscape\"\n",
    "OPTIONS = os.listdir(STORAGE_DATA + \"/train\")\n",
    "NUM_CLASSES = len(OPTIONS)\n",
    "PROBLEM_ID = \"landscape_classifier\"\n",
    "EXPERIMENT_TENSORBOARD_NAME = PROBLEM_ID\n",
    "EXPRIMENT_TENSORBOARD_PATH = \"../experiment/\"\n",
    "SEED_CODE = 131006 # Random id dùng cho sinh dữ liệu\n",
    "TRAIN_SIZE = 0.8 # 80% dữ liệu train sẽ được đem đi đào tạo, 20% cho validation\n",
    "NUM_SAMPLE_PER_CLASS = 4 # Số sample mỗi label dành cho học không gian embedding\n",
    "DROPOUT = 0.2 # Công dụng regularier, cấu hình cho nn.Dropout\n",
    "TRIPLER_MARGIN = 2.0 # Độ khác biệt tối thiểu giữa anchor và positive, dùng cho biệt hoá không gian embedding\n",
    "STRATEGY_ANCHOR_POSITIVE = \"hard\"\n",
    "DEVICE = \"cpu\"\n",
    "PATIENCE = 4 # Số lượt đợi không cải thiện\n",
    "LAMBDA_CLASSIFY = 1. # Trọng số đánh giá tầm quan trọng mục tiêu phân loại\n",
    "LAMBDA_EMBEDDING = 1. # Trọng số đánh giá tầm quan trọng mục tiêu biệt hoá không gian\n",
    "ILLUSTRATION_EXAMPLES = 1000 # Giới hạn số mẫu dùng cho show projector trong tensorboard\n",
    "MAX_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb5d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In thử các lớp\n",
    "print(OPTIONS)\n",
    "print(IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc24756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cấu hình pytorch đảm bảo thí nghiệm\n",
    "torch.manual_seed(SEED_CODE)\n",
    "random.seed(SEED_CODE)\n",
    "np.random.seed(SEED_CODE)\n",
    "torch.cuda.manual_seed(SEED_CODE)\n",
    "torch.cuda.manual_seed_all(SEED_CODE)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7fc60c",
   "metadata": {},
   "source": [
    "### Chuẩn bị dữ liệu huấn luyện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e426521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(IMG_SIZE),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(*NORMALIZE_IMAGE)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a42e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = torchvision.datasets.ImageFolder(STORAGE_DATA + \"/train\", transform=train_transform)\n",
    "\n",
    "# Chia tập train và validation\n",
    "train_size = int(len(full_dataset) * TRAIN_SIZE)\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Lấy bộ dữ liệu test\n",
    "test_dataset = torchvision.datasets.ImageFolder(STORAGE_DATA + \"/test\", transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1d5040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In thử thông tin bộ dữ liệu\n",
    "print(f\"Kích thước toàn bộ dữ liệu đào tạo: {len(full_dataset)}\")\n",
    "print(f\"Kích thước dữ liệu cho training: {train_size}\")\n",
    "print(f\"Kích thước dữ liệu cho validation: {val_size}\")\n",
    "print(f\"Kích thước dữ liệu cho test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14188c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiến hành tạo DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, persistent_workers=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, persistent_workers=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9e3ea2",
   "metadata": {},
   "source": [
    "### Kiến trúc mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e40c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lớp hành vi của vấn đề\n",
    "class LandscapeClassifier(NonCodeProblem):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(PROBLEM_ID, *args, **kwargs)\n",
    "        self._represent = RepresentLayer([\n",
    "            ImageRepresent(img_shape=IMG_SHAPE, patch_size=16, num_heads=1, phi_dim=PHI_DIM),\n",
    "            ImageRepresent(img_shape=IMG_SHAPE, patch_size=16, num_heads=1, phi_dim=PHI_DIM)\n",
    "        ], output_dim=PHI_DIM)\n",
    "        self._combine_repr = CoRepresentLayer(\n",
    "            [ CoRepresentUnit(2, phi_dim=PHI_DIM),\n",
    "              CoRepresentUnit(2, phi_dim=PHI_DIM)\n",
    "            ]\n",
    "        )\n",
    "        self._property = PropertyUnit(phi_dim=PHI_DIM)\n",
    "        self._task = ChooseOptions(1, options=OPTIONS, property_name=\"landscape\", phi_dim=PHI_DIM)\n",
    "    \n",
    "    def recognize_unknown(self, x, *args, **kwargs):\n",
    "        x = self._represent(x)\n",
    "        x = self._combine_repr(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x, skip_avatar : bool = False, *args, **kwargs):\n",
    "        x = self._represent(x)\n",
    "        x = self._combine_repr(x)\n",
    "\n",
    "        q = self._property(x)\n",
    "        q = self._task(x + q)\n",
    "\n",
    "        if skip_avatar:\n",
    "            return q\n",
    "        \n",
    "        return q, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63570c18",
   "metadata": {},
   "source": [
    "### Cấu hình huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b9529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viết lớp Learner dành riêng cho việc học đào tạo vấn đề\n",
    "class LandscapeClassifierLearner(LightningLearner):\n",
    "    def __init__(self, problem, *args, **kwargs):\n",
    "        super().__init__(problem, *args, **kwargs)\n",
    "        self._classify = nn.CrossEntropyLoss()\n",
    "        self._specialized_space = losses.ArcFaceLoss(num_classes=NUM_CLASSES, embedding_size=PHI_DIM, margin=TRIPLER_MARGIN)\n",
    "        self._train_accuracy = Accuracy(task=\"multiclass\", num_classes=NUM_CLASSES)\n",
    "        self._val_accuracy = Accuracy(task=\"multiclass\", num_classes=NUM_CLASSES)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # Kết hợp thêm chiến lược scheduler\n",
    "        optimizer = optim.AdamW(self._problem.parameters(), lr=DEFAULT_LR)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=PATIENCE - 2)\n",
    "        return { \"optimizer\" : optimizer, \"lr_scheduler\" : scheduler, \"monitor\" : \"val/loss\" }\n",
    "\n",
    "    def training_step(self, batch, batch_idx, *args, **kwargs):\n",
    "        x, y = batch\n",
    "        y_predicted = self(x)\n",
    "\n",
    "        loss, ce, triplet = self._aggerate_loss(y_predicted, y)\n",
    "        self._train_accuracy.update(y_predicted[0], y)\n",
    "        \n",
    "        self.log(\"train/loss\", loss, prog_bar=True, logger=True, on_epoch=True, on_step=True)\n",
    "        self.log(\"train/ce\", ce, prog_bar=True, logger=True, on_epoch=True)\n",
    "        self.log(\"train/triplet\", triplet, prog_bar=True, logger=True, on_epoch=True)\n",
    "        self.log(\"train/acc\", self._train_accuracy, prog_bar=True, on_epoch=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx, *args, **kwargs):\n",
    "        x, y = batch\n",
    "        y_predicted = self(x)\n",
    "\n",
    "        loss, ce, triplet = self._aggerate_loss(y_predicted, y)\n",
    "        self._val_accuracy.update(y_predicted[0], y)\n",
    "\n",
    "        self.log(\"val/loss\", loss, prog_bar=True, logger=True, on_epoch=True)\n",
    "        self.log(\"val/acc\", self._val_accuracy, prog_bar=True, logger=True, on_epoch=True)\n",
    "        self.log(\"val/ce\", ce, prog_bar=True, logger=True, on_epoch=True)\n",
    "        self.log(\"val/triplet\", triplet, prog_bar=True, logger=True, on_epoch=True)\n",
    "\n",
    "    def on_train_batch_end(self, outputs, batch, batch_idx):\n",
    "        lr = self.trainer.optimizers[0].param_groups[0]['lr']\n",
    "        self.log(\"lr\", lr, logger=True, on_epoch=True)\n",
    "\n",
    "    def _aggerate_loss(self, y_predicted, y, *args, **kwargs):\n",
    "        y_hat, emb = y_predicted\n",
    "\n",
    "        ce = self._classify(y_hat, y)\n",
    "        triplet = self._specialized_space(emb, y)\n",
    "\n",
    "        loss = LAMBDA_CLASSIFY * ce + LAMBDA_EMBEDDING * triplet\n",
    "\n",
    "        return loss, ce, triplet\n",
    "    \n",
    "    def test_step(self, batch, *args, **kwargs):\n",
    "        x, y = batch\n",
    "        y_predicted = self(x)\n",
    "\n",
    "        loss, __, __ = self._aggerate_loss(y_predicted, y)\n",
    "        self._val_accuracy.update(y_predicted[0], y)\n",
    "\n",
    "        self.log(\"test/loss\", loss, prog_bar=True, on_epoch=True, logger=True)\n",
    "        self.log(\"test/acc\", self._val_accuracy, prog_bar=True, logger=True, on_epoch=True)\n",
    "    \n",
    "    def _get_embedding(self, iterators):\n",
    "        # Hiển thị thử embedding\n",
    "        collected = 0\n",
    "\n",
    "        all_labels = []\n",
    "        all_embeds = []\n",
    "\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in iterators:\n",
    "                x, y = batch\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "\n",
    "                # Encode ảnh thành vector đặc trưng (ví dụ: self._problem.encode)\n",
    "                embedding = self._problem.recognize_unknown(x)\n",
    "\n",
    "                # all_imgs.append(x.cpu())\n",
    "                all_labels.append(y.cpu())\n",
    "                all_embeds.append(embedding.cpu())\n",
    "\n",
    "                collected += x.size(0)\n",
    "                if collected >= ILLUSTRATION_EXAMPLES:\n",
    "                    break  # Dừng sớm nếu vượt quá max_examples\n",
    "        \n",
    "        # all_imgs = torch.cat(all_imgs, dim=0)[:ILLUSTRATION_EXAMPLES]\n",
    "        all_labels = torch.cat(all_labels, dim=0)[:ILLUSTRATION_EXAMPLES]\n",
    "        all_embeds = torch.cat(all_embeds, dim=0)[:ILLUSTRATION_EXAMPLES]\n",
    "\n",
    "        return all_labels, all_embeds\n",
    "\n",
    "    def on_train_end(self):\n",
    "        all_labels, all_embeds = self._get_embedding(self.trainer.val_dataloaders)\n",
    "        self.logger.experiment.add_embedding(\n",
    "            mat=all_embeds,\n",
    "            metadata=[str(label.item()) for label in all_labels],\n",
    "            global_step=self.global_step,\n",
    "            \n",
    "            tag=\"train/embedding\"\n",
    "        )\n",
    "\n",
    "    def on_test_end(self):\n",
    "        all_labels, all_embeds = self._get_embedding(self.trainer.test_dataloaders)\n",
    "        self.logger.experiment.add_embedding(\n",
    "            mat=all_embeds,\n",
    "            metadata=[str(label.item()) for label in all_labels],\n",
    "            global_step=self.global_step,\n",
    "            tag=\"test/embedding\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a721ab",
   "metadata": {},
   "source": [
    "### Phối hợp các Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271ead1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo bộ giải quyết vấn đề\n",
    "solver = LandscapeClassifier()\n",
    "solver.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefdadab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In thử kiến trúc\n",
    "print(solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e80ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo bộ học\n",
    "learner = LandscapeClassifierLearner(solver)\n",
    "learner.compile()\n",
    "# Vẽ đồ thị lan truyền\n",
    "learner.example_input_array = torch.randn(1, *IMG_SHAPE, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7da4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thử hiển thị và chạy thử solver\n",
    "y_predicted = solver(torch.randn(32, *IMG_SHAPE))\n",
    "print(y_predicted[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f5d56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Thử in kích thước loader\n",
    "# imgs, labels = next(iter(train_loader))\n",
    "# print(imgs.shape)\n",
    "# y_hat = solver(imgs)\n",
    "# print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c7215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cấu hình logger, callbacks\n",
    "logger = TensorBoardLogger(EXPRIMENT_TENSORBOARD_PATH, EXPERIMENT_TENSORBOARD_NAME, log_graph=False)\n",
    "early = EarlyStopping(\"val/loss\", patience=PATIENCE, verbose=True)\n",
    "best_checkpoint = ModelCheckpoint(dirpath=f\"../database/{PROBLEM_ID}\", filename=\"best\", monitor=\"val/loss\", verbose=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad96c02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:   3%|▎         | 12/351 [00:14<07:02,  0.80it/s, v_num=5, train/loss_step=5.760, train/ce_step=1.770, train/triplet_step=3.990, val/loss=5.690, val/acc=0.164, val/ce=1.790, val/triplet=3.900, train/loss_epoch=5.700, train/ce_epoch=1.790, train/triplet_epoch=3.910, train/acc_epoch=0.186]"
     ]
    }
   ],
   "source": [
    "# Huấn luyện mô hình\n",
    "trainer = Trainer(accelerator=\"auto\", max_epochs=MAX_EPOCHS, logger=logger, callbacks=[early, best_checkpoint])\n",
    "trainer.fit(learner, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c649edcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
